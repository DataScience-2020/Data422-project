{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangler Group Project Report\n",
    "\n",
    "==============================================================\n",
    "\n",
    "Team Members:\n",
    "\n",
    "Name: Shi Chen\n",
    "\n",
    "Student ID: 54638177\n",
    "\n",
    "Name: Jian ZHOU\n",
    "\n",
    "Student ID: 51404140\n",
    "\n",
    "Date of submission: 23/10/2020\n",
    "\n",
    "==============================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Our team is hired by ABC Game development company. Our team is responsible for data collection which will help development department to make decision. \n",
    "\n",
    "##### Our tasks are divided into 3 parts:\n",
    "\n",
    "    First part is about game market information collection;\n",
    "\n",
    "    Second part is about new game storyline design;\n",
    "\n",
    "    Third part is about new game payment design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 Game market information collection\n",
    "####  \n",
    "\n",
    "\n",
    "#### Data Source: IGDB API\n",
    "\n",
    "Scource link (IGDB API documents): https://api-docs.igdb.com/#endpoints\n",
    "\n",
    "IGDB introduction: https://www.igdb.com/about \n",
    "\n",
    "\n",
    "#### Why choose this data source?\n",
    "\n",
    "* From the view of authority: \n",
    " \n",
    " the community and developers in this flat are generous, they wish to share data.\n",
    "\n",
    "* Professional: \n",
    " \n",
    " IGDB is games ”one-stop-infospot”, which allow users to do more with the information in order to explore and find games to play in a new way. From the authority point of view. And it contains 245,500 games, more than 35,647 members and involved 27,894 companies. It is very professional API resources.\n",
    " \n",
    "* It is free!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target \n",
    "\n",
    "In this part, we are going to generate information which will benefit to analysis the popular games. \n",
    "\n",
    "* Genre (market preference)\n",
    "* Age_rating (target user)\n",
    "* Developer map (parterners or competitors)\n",
    "* Keyword pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenges\n",
    "\n",
    "* Token\n",
    "\n",
    "Sarah and Christine are responsible for this part. To new hands, challenges are everywhere happens everyday. Scapping data from API, the first thing is to obtain \"Token\" from API Database. It is the key. We Follow the process list on API document, doing it step by step, though totally have no idea what will happen next. With Gulio's help, we eventrally can post require to IGDB API with Token. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* API documents\n",
    "\n",
    "There are a lot of information in the API documents, \"authentication\" \"Example\" \"Endpoints\" contains a lot of informations about the game dataset. We did not read them carefully in the beginning, and made problem when doing the data cleaning. When we realized it, we already waste a lot of time. This is a big lesson. Whenever collectiong data, the first thing is figure out what kind of data need to be collected, it must be clear and reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Coding\n",
    "\n",
    "We using Julia to do this part. Not easy at all. From \"post\" to generate string information from web, then transform them into JSON format then output as CSV. The process seems very clear, but when you doing it, there are a lot of small tricks waiting to stuck you. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Logic\n",
    "\n",
    "This is a very important part.As mentioned before, in the very begining, we generate some data, then we think it will work. But acturally we use the wrong logic, the data cannot be used, too many noice data, missing value data. After we define what is \"popular game\", how to filter them directly rather than scapping all the games' data. Things become clear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Correlation\n",
    "\n",
    "Here, the correlation means the relationship between main dataset and sub dataset. In the main game information dataset, there are plenty encoding values cannot be used directly. This encoding values need another sub dataset to decoding. That is why we generate 10 sub dataset. And there are some features' type are list, it is another challenge part. We have not solve yet.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Github\n",
    "\n",
    "Selflearn how to use Github. It is a challenge for us in the begining, but it is quite convinient and smart after we familiar with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Techniques\n",
    "\n",
    "In this part we use Julia as tool to scrapping games' information then using .csv as output data format, there are some wrapped function been used which will make life easy.\n",
    "\n",
    "To facilitate version control and collaboration, we use Github to manage the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Achieved and failed\n",
    "\n",
    "* Achieved\n",
    "\n",
    "1. Our main target dataset (the main popular games data) was generate successfully (filename: target_games_fellow.csv). It is in the Data422-project/IGDB/Docs directory. This file contains the top 500 popular games and 25 game's features information.\n",
    "\n",
    "(Popular games selection logic please refer to Data422-project/IGDB/Codes/IGDB_games_infor_scrap_main.ipnb section 1 keyword \"body_fellow\")\n",
    "\n",
    "2. Another 10 sub datasets (decoding dataset related to these 500 popular games), which can be used to do different group analysis. \n",
    "\n",
    "Such as game_ageRating_groupCount_plot.png and game_ageRating_groupCount.csv is using the data from game_ageRating sub dataset. You can do more as you like, such as genre groupcount, releaseDates analysis, game_theme groupcount and so on.\n",
    "\n",
    "* Failed\n",
    "\n",
    "1. Companies information sub dataset was generate in wrong coding. Have tried many ways but still not been solved yet.\n",
    "\n",
    "2. The companies world mapping is using the wrong data, so please use it carefully.\n",
    "\n",
    "\n",
    "* Haven't figure out\n",
    "Julia technique: \n",
    "1. Convert list column into a set; \n",
    "2. Join by list column; \n",
    "3. Groupby id summarize column value as set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Movie information collection\n",
    "####  \n",
    "\n",
    "#### Data Source: IMDB website & Twitter API\n",
    "IMDB does not provide an API to facilitate automated queries. However, we could scrape the web pages to get the data. Twitter API is also a convenient and reliable datasource.\n",
    "\n",
    "\n",
    "#### Why choose these data sources?\n",
    "\n",
    "* IMDb is the world's most popular and authoritative source for movie, TV and celebrity content to find ratings and reviews for the newest movie and TV shows.\n",
    "\n",
    "* Twitter API to search for keywords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target \n",
    "\n",
    "We focus on using movie dataset to support game design by discovering some of the prominent storyline and characters. \n",
    "\n",
    "* Movie \n",
    "* Storyline\n",
    "* Characters\n",
    "* Locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Challenges\n",
    "\n",
    "* Coding\n",
    "\n",
    ">Jay is responsible for this part. We don't have an API to use for the movies and characters, and the IMDB has a very large dataset. For movies, we name, year, rating, votes, directors and cast member from two different web pages. \n",
    "\n",
    ">The Programming languages used are R (for twitter API, sf map, NLP wordcloud2), Julia (for IMDB web scraping) and Java (for Clavin storyline locations extraction).\n",
    "\n",
    "* Big Data\n",
    "\n",
    ">There are millions of records for cast members, in addition to decades’ movie and stars numerical and text data. IMDB contains around 10,000 movies for each year’s record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Techniques\n",
    "\n",
    ">NLP analysis to extract geographic locations from movie stories, and created wordcloud for characters and storylines from both IGDB and IMDB datasets.\n",
    "\n",
    ">Incrementally save data to files.\n",
    "\n",
    ">Two steps approach: \n",
    ">>1. Movie data with IMDb ID. \n",
    ">>2. Scrape cast page based on movie table.\n",
    "\n",
    ">Multitasking process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Achieved and Issues\n",
    "\n",
    ">To avoid ethical and privacy problems, only text mining fictitious characters instead of real names.\n",
    "\n",
    ">Finally gathered 0.3 million records cast member dataset, in addition to 10 years’ movie and stars numerical and text data, around 15MB movie and stars data, as well as a 12MB cast table, not including the text files for storyline and characters, which are also big enough to do text mining. This cast table especially can be used for other data scientists for other purposes, such as to find the most valuable actors / actresses throughout the years, when combined with movie and / or stars table, which possess rating, score, voting etc.\n",
    "\n",
    ">NLP analysis to extract geographic locations from movie stories, and created wordcloud for characters and storylines from both IGDB and IMDB datasets. CLAVIN on GitHub to extract geographic information from text files, but went through a long process to install it on local computer.\n",
    "\n",
    ">FlipTextAnalysis library in R to do NLP sentiment analysis in wordcloud2.\n",
    "\n",
    ">rtweet API to get game and movie text and wrote code snippets to filter out stop words.\n",
    "\n",
    ">Simple Features (sf) R library combined with a world geojson file I found online to plot storyline locations in 2010 and 2020 and found that India, China, France, Mexico and Japan are some of the hotspots. The popularity of India continues but China decreases.\n",
    "\n",
    ">Open Source projects are sometimes not so perfect in case of Clavin producing some unnecessary data, making the output untidy, but it’s a nice attempt. The graph output still gives us some intuitive peeking into the data we managed to retrieve from both IGDB and IMDB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
